# Neural Text Summarization: A Critical Evaluation

## タスク
文書要約

## 貢献点
現在の文書要約タスクのコーパス、モデル、評価指標についての批判

## モデルについての批判

### 曖昧性の指摘
文書要約タスクはこれまで様々なモデルが提案されたが、SOTAでもLead3より多少高い程度である。
これは、モデルに1つの関連する要約と追加情報のないドキュメントが与えられるだけの現在の設定では、要約のタスクの制約が少なく、解決するには曖昧すぎるためである。

これを示すために、複数のアノテータが重要と思った文を抽出するときに、一致するものを測定した。アノテータが文書を要約を書くときに、元のソースとなった文を強調してもらった。

![](https://i.imgur.com/0J9BPzr.png)

unconstrainedは、記事を与えられ、重要と思われる部分を含むように要約を書く設定で、
constrainedは、記事と3つのそれに関連する人手で作られた質問が与えられ、その質問の回答を含むように要約を書く設定である。

多くの人が重要だと思う文章はあまり多くなかった。
また、質問を追加情報として与えることによって、一致する文章が大幅に増加した。

### 分野依存性の指摘
![](https://i.imgur.com/gl6vjbQ.png)
CNN/DailyMailなどのニュース要約タスクは、明らかに文書の前半を抽出する確率が高い。一方で、他の分野のタスクはこの傾向はないことから、モデルが特定分野に依存している可能性がある。

最初の3文を正解データとして複数の文書要約モデルで実験を行なった。
![](https://i.imgur.com/wQ5RrXN.png)

最初の3文を正解データとした場合は、非常に高いスコアが出たため現在のモデルはコーパスのバイアスを学習していると言える。

### 多様性の検証
![](https://i.imgur.com/4cmso6n.png)
上がunigramのオーバーラップで、下が4-gramのオーバラップの割合。
unigramが高いのは、各モデルの語彙の共有部分が大きいからと思われる。
どのモデルも高いオーバーラップがあったことから、コーパスに抽出しやすい箇所があるか、モデルの学習性能が弱い可能性がある。


## コーパスの指摘
コーパスは、スクレイピングすることで作られるが、その過程でかなりのノイズを含んでいる。
CNN/DailyMailは、訓練データの0.47%、検証データの5.92%、テストデータの4.19%にノイズが含まれていた。
また、Newsroom datasetは、訓練データの3.21%、検証データの3.22%、テストデータの3.17%にノイズが含まれていた。

## 評価指標の指摘
文書要約で使われるROUGEスコアと人出評価の相関を実験した。
CNN/DailyMailを使用した。
人出評価の評価指標として、
relevance(ソース文から重要な情報を取れているか)
consistency(ソース文と矛盾がないか)
fluency(要約文それぞれの質)
coherence(要約文全体の質)
の4つで評価した。
![](https://i.imgur.com/EqASNdz.png)

ピアソン相関係数と、ケンドールの順位相関係数で相関を計算した。
結果としてあまり相関がないことがわかった。
ROUGEスコアは、単語の一致率しか見れていないので他の要素を加味するべきである。
